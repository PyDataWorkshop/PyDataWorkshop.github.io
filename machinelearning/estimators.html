

<!-- ############################################################################## -->
<h3>Estimators</h3>
<ul>
<li> Scikit-learn provides an object-oriented interface centered around the concept of an Estimator. </li>
<li> According to the scikit-learn tutorial “<i>An estimator is any object that learns from data; it may be a classification, 
regression or clustering algorithm or a transformer that extracts/filters useful features from raw data.</i>” 	</li>
<\ul>




<li> The <b><tt>Estimator.fit</tt></b> method sets the state of the estimator based on the training data. 
<li> Usually, the data is comprised of a two-dimensional numpy array X of shape <b><tt>(n\_samples, n\_predictors) </tt></b>that holds the so-called feature matrix and a one-dimensional numpy array y that holds the responses. 
<li> Some estimators allow the user to control the fitting behavior. 
<li> For example, the <b><tt>sklearn.linear_model.LinearRegression</tt></b> estimator allows the user to specify whether or not to fit an intercept term. 
<li> This is done by setting the corresponding constructor arguments of the estimator object:
<\ul>

<!-- ############################################################################## -->

\begin{figure}
\centering
\includegraphics[width=1.1\linewidth]{sklcass/sklclass1a}

\end{figure}

\large
<pre>
<code>
from sklearn.linear_model import LinearRegression
est = LinearRegression(fit_intercept=False)
<\code>
<\pre>

The docstring of the estimator shows you all available arguments – in IPython simply use LinearRegression? to view the docstring.

<!-- ############################################################################## -->

\Large
<ul>
<li> During the fitting process, the state of the estimator is stored in instance attributes that have a trailing underscore ('\_'). 
<li> For example, the coefficients of a LinearRegression estimator are stored in the attribute <b><tt>coef\_}:
<\ul>


<!-- ############################################################################## -->

<pre>
<code>
import numpy as np

# random training data
X = np.random.rand(10, 2)
y = np.random.randint(2, size=10)
est.fit(X, y)
est.coef_   # access coefficients

# Output : array([ 0.33176871,  0.34910639])
<\code>
<\pre>

<!-- ############################################################################## -->

<ul>
<li> Estimators that can generate predictions provide a Estimator.predict method.
<li> In the case of regression, Estimator.predict will return the predicted regression values; it will return the corresponding class labels in the case of classification.
<li>  Classifiers that can predict the probability of class membership have a method <b><tt>Estimator.predict\_proba} that returns a two-dimensional numpy array of shape <b><tt>(n\_samples, n\_classes)} where the classes are lexicographically ordered.
<\ul>



<!-- ############################################################################## -->

\textbf{Estimators: Transformers}
<ul>
<li> Finally, there is a special type of Estimator called Transformer which transforms the input data — e.g. selects a subset of the features or extracts new features based on the original ones.
<li> In addition to a fit method, a Transformer object provides the following methods:
<\ul>



<!-- ############################################################################## -->

\Large
<pre>
	<code>
class Transformer(Estimator):

def transform(self, X):
"""Transforms the input data. """
# transform ``X`` to ``X_prime``
return X_prime
<\code>
<\pre>

<!-- ############################################################################## -->

<ul>
<li> Usually, a Transformer does not provide a predict method, but in some cases it may.
<li> One transformer that we will use in this posting is <b><tt>sklearn.preprocessing.StandardScaler}. 
<li> This transformer centers each predictor in X to have zero mean and unit variance:
<\ul>


<!-- ############################################################################## -->

In [6]:
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler(copy=True)  # always copy input data (don't modify in-place)
X_centered = scaler.fit(X).transform(X)
scaler.mean_  # mean that will be subtracted upon transform
Out[6]:
array([ 0.48261456,  0.48636312])
For more information on scikit-learn please consult the detailed user guide or walk through the excellent tutorial.


	\huge
\[ \mbox{ Classification with Scikit-Learn} \]

<!-- ############################################################################## -->

\textbf{Understanding Classification}\\
Although regression and classification appear to be very different they are in fact similar problems.

<ul>
<li> In regression our predictions for the response are real-valued numbers
<li> on the other hand, in classification the response is a mutually exclusive class label 
<li> Example ``\textit{Is the email spam?}" or ``\textit{Is the credit card transaction fraudulent?}".
<\ul>


<!-- ############################################################################## -->


 	\Large
 	\textbf{Binary Classsification Problems}\\
 <ul>
<li> If the number of classes is equal to two, then we call it a binary classification problem; if there are more than two classes, then we call it a multiclass classification problem.
<li>  In the following we will assume binary classification because it’s the more general case, and — we can always represent a multiclass problem as a sequence of binary classification problems.
<\ul>


<!-- ############################################################################## -->

	\Large
\textbf{Credit Card Fraud}
<ul>
<li> We can also think of classification as a function estimation problem where the function that we want to estimate separates the two classes. 
<li> This is illustrated in the example below where our goal is to predict whether or not a credit card transaction is fraudulent
<li> he dataset is provided by James et al., \textbf{Introduction to Statistical Learning}.
<\ul>



<!-- ############################################################################## -->

	\Large
\vspace{-1cm}
\textbf{Credit Card Fraud}
\begin{figure}
\centering
\includegraphics[width=1.2\linewidth]{sklcass/sklclass1}

\end{figure}


<!-- ############################################################################## -->

	\Large
\textbf{Credit Card Fraud}
\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{sklcass/sklclass2}

\end{figure}



<!-- ############################################################################## -->

	\Large
	\textbf{Credit Card Fraud}
<ul>
<li> 	On the left you can see a scatter plot where fraudulent cases are red dots and non-fraudulent cases are blue dots. 
<li> A good separation seems to be a vertical line at around a balance of 1400 as indicated by the boxplots on the next slide.
<\ul>
	



<!-- ############################################################################## -->

	
	\begin{figure}
\centering
\includegraphics[width=0.95\linewidth]{sklcass/sklclass3}

\end{figure}

	


<!-- ###############################################################################===

\begin{figure}
\centering
\includegraphics[width=0.9\linewidth]{sklcass/sklclass4}

\end{figure}

<!-- ###############################################################################===

	
	\Large
\textbf{Simple Approach - Linear Regression}
<ul>
<li> A simple approach to binary classification is to simply encode default as a numeric variable with 'Yes' == 1 and 'No' == -1; fit an Ordinary Least Squares regression model and use this model to predict the response as 'Yes' if the regressed value is higher than 0.0 and 'No' otherwise. 
<li> The points for which the regression model predicts 0.0 lie on the so-called decision surface — since we are using a linear regression model, the decision surface is linear as well.
<\ul>



<!-- ###############################################################################===

The example below illustrates this. Note that we use the <b><tt>sklearn.linear\_model.LinearRegression} class in scikit-learn instead of the statsmodels.api.OLS class in statsmodels – they both implement the same procedure.

<!-- ###############################################################################===

\begin{figure}
\centering
\includegraphics[width=0.99\linewidth]{sklcass/sklclass6}
\end{figure}


<!-- ###############################################################################===

\begin{figure}
\centering
\includegraphics[width=0.99\linewidth]{sklcass/sklclass7}

\end{figure}


<!-- ###############################################################################===

<ul>
<li> Points that lie on the left side of the decision boundary will be classified as negative; 
<li> Points that lie on the right side, positive. 
<\ul>

The implementation of plot_surface can be found in the Appendix. 


<!-- ###############################################################################===

	\Large
\textbf{Confusion Matrix}
<ul>
<li> We can assess the performance of the model by looking at the confusion matrix — a cross tabulation of the actual and the predicted class labels. 

<li> The correct classifications are shown in the diagonal of the confusion matrix. The off-diagonal terms show you the \textbf{classification errors}. 
<li> A condensed summary of the model performance is given by the \textbf{misclassification rate} determined simply by dividing the number of errors by the total number of cases.
<\ul>



<!-- ###############################################################################===

\textbf{Confusion Matrix}\begin{figure}
\centering
\includegraphics[width=0.95\linewidth]{sklcass/sklclass8}

\end{figure}

<!-- ###############################################################################===

\textbf{Confusion Matrix}
\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{sklcass/sklclass9}

\end{figure}



<!-- ###############################################################################===

	\large
	\textbf{Cross Validation}
<ul>
<li> In this example we are assessing the model performance on the same data that we used to fit the model. 
<li> This might be a biased estimate of the models performance, for a classifier that simply memorizes the training data has zero training error but would be totally useless to make predictions.
<li>  It is much better to assess the model performance on a separate dataset called the test data.
<li>  Scikit-learn provides a number of ways to compute such held-out estimates of the model performance. <li> One way is to simply split the data into a \textbf{training set} and \textbf{testing set}.
<\ul>


<!-- ###############################################################################===

\begin{figure}
\centering
\includegraphics[width=0.99\linewidth]{sklcass/sklclass10}

\end{figure}


<!-- ###############################################################################===

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{sklcass/sklclass11}

\end{figure}


